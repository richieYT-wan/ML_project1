{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from proj1_helpers import *\n",
    "from preprocessing import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "y_train, tx_train, ids_train = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ids_train)\n",
    "tx_train.shape\n",
    "#250000 data points, 30 features per data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early exploration \n",
    "**Goal : making sure the basic functions work, testing unchanged vs normalized input data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing weights, sampling data\n",
    "w0 = np.random.randn(tx_train.shape[1],1)\n",
    "#Sampling a few datapoints out of the 250000\n",
    "n_samples = 5000\n",
    "\n",
    "y_tr_sampled, tx_tr_sampled = sample_data(y_train,tx_train,n_samples)\n",
    "y_tr_norm, tx_temp = sample_data(y_train,tx_train,n_samples)\n",
    "#standardizing the input\n",
    "tx_tr_norm, _, _ = standardize(tx_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd normal tx, loss: 3196.463945095456 \n",
      " [[ 0.01890528]\n",
      " [ 0.41740932]\n",
      " [-0.176445  ]]\n",
      "sgd std tx, loss:  0.5520143028253306 \n",
      " [[ 0.26417737]\n",
      " [ 0.40882269]\n",
      " [-0.1338973 ]]\n"
     ]
    }
   ],
   "source": [
    "#Using SGD\n",
    "w_sampled_sgd, loss_sampled_sgd = least_squares_SGD(y_tr_sampled, \n",
    "                                           tx_tr_sampled,\n",
    "                              w0, 500, 1e-7)\n",
    "\n",
    "w_norm_sgd, loss_norm_sgd = least_squares_SGD(y_tr_norm, tx_tr_norm,\n",
    "                              w0, 300, 1e-2)\n",
    "print(\"sgd normal tx, loss:\",loss_sampled_sgd,\"\\n\",w_sampled_sgd[0:3])\n",
    "print(\"sgd std tx, loss: \", loss_norm_sgd,\"\\n\",w_norm_sgd[0:3])\n",
    "#print(w_norm_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gd normal tx, loss: 4359.76458056838 \n",
      " [[ 0.01597099  0.01600354  0.01597099 ...  0.01600354  0.01597099\n",
      "   0.01600354]\n",
      " [ 0.4106628   0.41035555  0.4106628  ...  0.41035555  0.4106628\n",
      "   0.41035555]\n",
      " [-0.18392441 -0.18447188 -0.18392441 ... -0.18447188 -0.18392441\n",
      "  -0.18447188]]\n",
      "gd std tx, loss:  0.5094346330947049 \n",
      " [[ 0.19303652]\n",
      " [ 0.37707852]\n",
      " [-0.20378363]]\n"
     ]
    }
   ],
   "source": [
    "#Using GD\n",
    "w_sampled_gd, loss_sampled_gd = least_squares_GD(y_tr_sampled,\n",
    "                                                tx_tr_sampled,\n",
    "                                                w0, 300,1e-7)\n",
    "w_norm_gd, loss_norm_gd = least_squares_SGD(y_tr_norm, tx_tr_norm,\n",
    "                              w0, 500, 1e-2)\n",
    "print(\"gd normal tx, loss:\",loss_sampled_gd,\"\\n\",w_sampled_gd[0:3])\n",
    "print(\"gd std tx, loss: \", loss_norm_gd,\"\\n\",w_norm_gd[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LS normal eq, loss: 0.3396868094770356 \n",
      " [ 8.03494347e-05 -7.20202267e-03 -6.05417273e-03]\n",
      "LS normal eq, loss: 0.33968938634802587 \n",
      " [ 8.21350623e-05 -7.21942061e-03 -6.00961895e-03]\n"
     ]
    }
   ],
   "source": [
    "#Using normal eq\n",
    "n_samples = 200000\n",
    "\n",
    "y_normal, temp = sample_data(y_train,tx_train,n_samples)\n",
    "#standardizing the input\n",
    "tx_normal, _, _ = standardize(temp)\n",
    "w_normal, loss_normal = least_squares(y_train,tx_train)\n",
    "print(\"LS normal eq, loss:\",loss_normal,\"\\n\",w_normal[0:3])\n",
    "\n",
    "w_ridge, loss_ridge = ridge_regression(y_train,tx_train,5e-4)\n",
    "print(\"LS normal eq, loss:\",loss_ridge,\"\\n\",w_ridge[0:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((568238, 30), (568238,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test.shape, ids_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../output/' # TODO: fill in desired name of output file for submission\n",
    "\n",
    "#Creating the submissions for each method of \n",
    "y_pred_gd = predict_labels(w_norm_gd, tX_test)\n",
    "y_pred_sgd = predict_labels(w_norm_sgd,tX_test)\n",
    "y_pred_normal = predict_labels(w_normal,tX_test)\n",
    "y_pred_ridge = predict_labels(w_ridge,tX_test)\n",
    "create_csv_submission(ids_test, y_pred_sgd,\n",
    "                      OUTPUT_PATH+\"submission_sgd.csv\")\n",
    "create_csv_submission(ids_test, y_pred_gd, \n",
    "                      OUTPUT_PATH+\"submission_gd.csv\")\n",
    "create_csv_submission(ids_test, y_pred_normal,\n",
    "                      OUTPUT_PATH+\"submission_normaleq.csv\")\n",
    "create_csv_submission(ids_test, y_pred_ridge,\n",
    "                      OUTPUT_PATH+\"submission_ridge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
