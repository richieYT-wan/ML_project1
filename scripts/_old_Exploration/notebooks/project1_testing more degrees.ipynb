{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "THIS VERSION REMOVES THE 29TH COLUMN FROM CLUSTER0\n",
      "PREPROCESSING TRAIN DATA \n",
      " Clustering w.r.t. to PRI_jet_num numbers\n",
      "Prediction targets detected. Using a training set. \n",
      " Returning clusterized dataset and targets. \n",
      "\n",
      "Getting indices of columns to remove before taking log.\n",
      "10 features deleted\n",
      "7 features deleted\n",
      "0 features deleted\n",
      "0 features deleted\n",
      "Taking the log of selected features\n",
      "\n",
      " Removing features where all rows are -999 or 0. Returning indices for later\n",
      "Replacing -999 values with median\n",
      "Standardizing : Setting mean to 0 and variance to 1\n",
      "Preprocessing done\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%timeit\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from preprocessing import *\n",
    "from train_tune import *\n",
    "from proj1_helpers import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "DATA_TRAIN_PATH = '../data/train.csv' # TODO: download train data and supply path here \n",
    "\n",
    "#loading data\n",
    "\n",
    "y, tx_train, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "names= get_feature_names(DATA_TRAIN_PATH)\n",
    "name2num,num2name = mapping(DATA_TRAIN_PATH)\n",
    "#Train preprocessing\n",
    "print(\"THIS VERSION REMOVES THE 29TH COLUMN FROM CLUSTER0\")\n",
    "from preprocessing import cluster_preprocessing_train\n",
    "tx0, y0, tx1, y1, tx2, y2, tx3, y3, id0, id1, id2, id3 = cluster_preprocessing_train(tx_train,y,num2name,f=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-15, 6.10540230e-15, 3.72759372e-14, 2.27584593e-13,\n",
       "       1.38949549e-12, 8.48342898e-12, 5.17947468e-11, 3.16227766e-10,\n",
       "       1.93069773e-09, 1.17876863e-08, 7.19685673e-08, 4.39397056e-07,\n",
       "       2.68269580e-06, 1.63789371e-05, 1.00000000e-04])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 14 is out of bounds for axis 0 with size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-18fa83f7d60e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 14 is out of bounds for axis 0 with size 12"
     ]
    }
   ],
   "source": [
    "plt.plot(test2[14,2])\n",
    "plt.plot(train2[14,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#======== CV for Cluster 2 ========#\n",
      "Iterating. Testing 15 lambdas for current degree = 4\n",
      "Iterating. Testing 15 lambdas for current degree = 5\n",
      "Iterating. Testing 15 lambdas for current degree = 6\n",
      "Iterating. Testing 15 lambdas for current degree = 7\n",
      "Iterating. Testing 15 lambdas for current degree = 8\n",
      "Iterating. Testing 15 lambdas for current degree = 9\n",
      "Iterating. Testing 15 lambdas for current degree = 10\n",
      "Iterating. Testing 15 lambdas for current degree = 11\n",
      "Iterating. Testing 15 lambdas for current degree = 12\n",
      "Iterating. Testing 15 lambdas for current degree = 13\n",
      "Iterating. Testing 15 lambdas for current degree = 14\n",
      "Iterating. Testing 15 lambdas for current degree = 15\n",
      "Getting best degree and lambda\n",
      "Ridge regression : getting optimal weights with best degree (15), lambda (3.727593720314938e-14)\n",
      "Done, returning optimal weight, degree, lambda \n",
      " And train and test loss arrays for visualization\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 14 is out of bounds for axis 0 with size 12",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a8a445ab41a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m                                                              \u001b[0mlambdas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdegrees\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                                                              loss=True)\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mcv_viz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_opt2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlambdas\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_opt2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0md_opt2\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"more_degrees_c2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;31m#----------------3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 14 is out of bounds for axis 0 with size 12"
     ]
    }
   ],
   "source": [
    "#K-fold CV\n",
    "k_fold=5\n",
    "\n",
    "lambdas = np.logspace(-15,-4,15)\n",
    "degrees = np.array(range(4,16))\n",
    "\n",
    "#print(\"#======== CV for Cluster 0 ========#\")\n",
    "#w_opt0, d_opt0, la0, train0, test0 = crossval_ridge_gridsearch(y0,tx0,k_fold,\n",
    "#                                                             lambdas,degrees,\n",
    "#                                                             loss=True)\n",
    "#cv_viz(d_opt0,lambdas,train0[d_opt0-1,:],test0[d_opt0-1,:],save=\"more_degrees_c0\")\n",
    "##----------------1\n",
    "#print(\"#======== CV for Cluster 1 ========#\")\n",
    "#w_opt1, d_opt1, la1, train1, test1 = crossval_ridge_gridsearch(y1,tx1,k_fold,\n",
    "#                                                             lambdas,degrees,\n",
    "#                                                             loss=True)\n",
    "#cv_viz(d_opt1,lambdas,train1[d_opt1-1,:],test0[d_opt1-1,:],save=\"more_degrees_c1\")\n",
    "#\n",
    "##----------------2\n",
    "print(\"#======== CV for Cluster 2 ========#\")\n",
    "w_opt2, d_opt2, la2, train2, test2 = crossval_ridge_gridsearch(y2,tx2,k_fold,\n",
    "                                                             lambdas,degrees,\n",
    "                                                             loss=True)\n",
    "cv_viz(d_opt2,lambdas,train2[d_opt2-1,:],test0[d_opt2-1,:],save=\"more_degrees_c2\")\n",
    "\n",
    "#----------------3\n",
    "print(\"#======== CV for Cluster 3 ========#\")\n",
    "w_opt3, d_opt3, la3, train3, test3 = crossval_ridge_gridsearch(y3,tx3,k_fold,\n",
    "                                                             lambdas,degrees,\n",
    "                                                             loss=True)\n",
    "cv_viz(d_opt3,lambdas,train3[d_opt3-1,:],test0[d_opt3-1,:],save=\"more_degrees_c3\")\n",
    "\n",
    "degs=[d_opt0,d_opt1,d_opt2,d_opt3]\n",
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "THIS VERSION REMOVES THE 29TH COLUMN FROM CLUSTER0\n",
      "PREPROCESSING TRAIN DATA \n",
      " Clustering w.r.t. to PRI_jet_num numbers\n",
      "Prediction targets detected. Using a training set. \n",
      " Returning clusterized dataset and targets. \n",
      "\n",
      "Getting indices of columns to remove before taking log.\n",
      "10 features deleted\n",
      "7 features deleted\n",
      "0 features deleted\n",
      "0 features deleted\n",
      "Taking the log of selected features\n",
      "\n",
      " Removing features where all rows are -999 or 0. Returning indices for later\n",
      "Replacing -999 values with median\n",
      "Standardizing : Setting mean to 0 and variance to 1\n",
      "Preprocessing done\n",
      "#======== CV for Cluster 0 ========#\n",
      "Iterating. Testing 15 lambdas for current degree = 4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Sanity check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 5, 11, 11]\n",
      "(172,) (116,) (331,) (331,)\n",
      "(99913, 19) (77544, 23) (50379, 30) (22164, 30)\n",
      "(99913, 172) (77544, 116) (50379, 331) (22164, 331)\n",
      "(227458, 172) (175338, 116) (114648, 331) (50794, 331)\n"
     ]
    }
   ],
   "source": [
    "#Veryfing we get the correct results\n",
    "tx_poly0 = build_poly(tx0,d_opt0)\n",
    "w_test0, _ = ridge_regression(y0, tx_poly0, la0)\n",
    "\n",
    "tx_poly1 = build_poly(tx1,d_opt1)\n",
    "w_test1, _ = ridge_regression(y1, tx_poly1, la1)\n",
    "\n",
    "tx_poly2 = build_poly(tx2, d_opt2)\n",
    "w_test2, _ = ridge_regression(y2, tx_poly2, la2)\n",
    "\n",
    "tx_poly3 = build_poly(tx3,d_opt3)\n",
    "w_test3, _ = ridge_regression(y3, tx_poly3, la3)\n",
    "\n",
    "print(\"hoping for the best\")\n",
    "print(w_opt0 == w_test0,\"\\n\")\n",
    "print(w_opt1 == w_test1,\"\\n\")\n",
    "print(w_opt2 == w_test2,\"\\n\")\n",
    "print(w_opt3 == w_test3,\"\\n\")\n",
    "print(degs)\n",
    "print(w_opt0.shape, w_opt1.shape, w_opt2.shape, w_opt3.shape)\n",
    "print(tx0.shape, tx1.shape, tx2.shape, tx3.shape)\n",
    "print(build_poly(tx0,9).shape, build_poly(tx1,5).shape,build_poly(tx2,11).shape,build_poly(tx3,11).shape)\n",
    "print(test0.shape, test1.shape, test2.shape, test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal prediction\n"
     ]
    }
   ],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download test data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "OUTPUT_PATH = '../finalsubmit/' # TODO: fill in desired name of output file for submission\n",
    "#Test preprocessing\n",
    "test0, i0, test1, i1, test2, i2, test3, i3 = cluster_preprocessing_test(tX_test, id0, id1, id2,id3, [9,5,11,11], degs,f=\"median\")\n",
    "#Prediction\n",
    "yclusterpred_opt = cluster_predict(w_opt0,w_opt1,w_opt2,w_opt3,\n",
    "                               test0,test1,test2,test3,\n",
    "                               i0,i1,i2,i3,how=\"normal\")\n",
    "\n",
    "create_csv_submission(ids_test, yclusterpred_opt, OUTPUT_PATH+\"CV_RIDGE_CORRECTEDLOGFEATURESwMedian.csv\")\n",
    "\n",
    "\n",
    "best = \"degs = {},{},{},{} \\n lambdas = {:e}, \\n {:e}, \\n {:e} \\n {:e}\".format(d_opt0,d_opt1,d_opt2,d_opt3,la0,la1,la2,la3)\n",
    "file1 = open(\"bestparams_ridge_CORRECTEDLOGFEATURESwMedian\",\"w\") \n",
    "file1.write(best)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
